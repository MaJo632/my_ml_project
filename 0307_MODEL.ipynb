{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, roc_auc_score, roc_curve, classification_report, f1_score, fbeta_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>target</th>\n",
       "      <th>most_frequ_reading_rem</th>\n",
       "      <th>mean_counter_coeff</th>\n",
       "      <th>mean_consommation_per_month</th>\n",
       "      <th>mean_months</th>\n",
       "      <th>elec_max</th>\n",
       "      <th>gaz_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>train_Client_33962</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>113.27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>train_Client_32174</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.11</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>train_Client_18868</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>70.77</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>train_Client_39728</td>\n",
       "      <td>11</td>\n",
       "      <td>310</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>144.65</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_34246</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>120.93</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disrict           client_id  client_catg  region  target   \n",
       "0       63  train_Client_33962           11     101    0.00  \\\n",
       "1       62  train_Client_32174           11     301    0.00   \n",
       "2       69  train_Client_18868           11     107    0.00   \n",
       "3       62  train_Client_39728           11     310    0.00   \n",
       "4       60  train_Client_34246           11     101    0.00   \n",
       "\n",
       "   most_frequ_reading_rem  mean_counter_coeff  mean_consommation_per_month   \n",
       "0                    6.00                1.00                       113.27  \\\n",
       "1                    6.00                1.00                         8.11   \n",
       "2                    6.00                1.00                        70.77   \n",
       "3                    6.00                1.00                       144.65   \n",
       "4                    6.00                1.00                       120.93   \n",
       "\n",
       "   mean_months  elec_max  gaz_max  \n",
       "0         4.00         1        1  \n",
       "1         3.40         1        1  \n",
       "2         4.00         1        1  \n",
       "3         4.11         1        0  \n",
       "4         3.96         1        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned/train.csv')\n",
    "df_test = pd.read_csv('data/cleaned/test.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Target, Drop ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['target']\n",
    "X_train = df.drop(['target', 'client_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105312"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper: Check specific columns:\n",
    "X_train.iloc[:,5].sort_values(ascending=False).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>most_frequ_reading_rem</th>\n",
       "      <th>mean_counter_coeff</th>\n",
       "      <th>mean_consommation_per_month</th>\n",
       "      <th>mean_months</th>\n",
       "      <th>elec_max</th>\n",
       "      <th>gaz_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>113.27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.11</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disrict  client_catg  region  most_frequ_reading_rem  mean_counter_coeff   \n",
       "0       63           11     101                    6.00                1.00  \\\n",
       "1       62           11     301                    6.00                1.00   \n",
       "\n",
       "   mean_consommation_per_month  mean_months  elec_max  gaz_max  \n",
       "0                       113.27         4.00         1        1  \n",
       "1                         8.11         3.40         1        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper (compare X_train and X_test below):\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split target from test data\n",
    "y_test = df_test['target']\n",
    "X_test = df_test.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>months_number</th>\n",
       "      <th>gaz</th>\n",
       "      <th>consommation_per_month</th>\n",
       "      <th>elec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>104</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>117.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disrict  client_catg  region  reading_remarque  counter_coefficient   \n",
       "0       69           11     104              8.00                 1.00  \\\n",
       "1       62           11     301              6.00                 1.00   \n",
       "\n",
       "   months_number  gaz  consommation_per_month  elec  \n",
       "0           4.00    0                   52.00     1  \n",
       "1           4.00    0                  117.75     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper (compare X_train and X_test):\n",
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- consommation_per_month\n- counter_coefficient\n- elec\n- gaz\n- months_number\n- ...\nFeature names seen at fit time, yet now missing:\n- elec_max\n- gaz_max\n- mean_consommation_per_month\n- mean_counter_coeff\n- mean_months\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m scaler = StandardScaler()\n\u001b[32m      2\u001b[39m X_train = scaler.fit_transform(X_train)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_test = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Maria\\Desktop\\neuefische\\my_ml_project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Maria\\Desktop\\neuefische\\my_ml_project\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1059\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1061\u001b[39m copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1074\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_mean:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Maria\\Desktop\\neuefische\\my_ml_project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2836\u001b[39m     _estimator,\n\u001b[32m   2837\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2843\u001b[39m     **check_params,\n\u001b[32m   2844\u001b[39m ):\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2846\u001b[39m \n\u001b[32m   2847\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Maria\\Desktop\\neuefische\\my_ml_project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2775\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- consommation_per_month\n- counter_coefficient\n- elec\n- gaz\n- months_number\n- ...\nFeature names seen at fit time, yet now missing:\n- elec_max\n- gaz_max\n- mean_consommation_per_month\n- mean_counter_coeff\n- mean_months\n- ...\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling the imbalanced\n",
    "ros = RandomOverSampler(random_state=RSEED)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "sns.countplot(x=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model 1: Decision Tree\n",
    "<span style=\"color:red\">X_train and X_test need to have the same columns!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline model 1: Decision tree\n",
    "baseline_tree = DecisionTreeClassifier(random_state=RSEED, max_depth=3)\n",
    "baseline_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Decision tree has {baseline_tree.tree_.node_count} nodes with maximum depth {baseline_tree.tree_.max_depth}.')\n",
    "print(f'On average there are ca. {X_train.shape[0]/baseline_tree.tree_.node_count:.1f} data points in each leaf.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "dectree_plot = plot_tree(baseline_tree, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make probability predictions for X_train\n",
    "train_probs1 = baseline_tree.predict_proba(X_train)[:, 1]\n",
    "train_predictions1 = baseline_tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, train_predictions1))\n",
    "print(classification_report(y_train, train_predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make probability predictions test data\n",
    "test_probs1 = baseline_tree.predict_proba(X_test)[:, 1]\n",
    "test_predictions1 = baseline_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, test_probs1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, test_predictions1))\n",
    "print(classification_report(y_test, test_predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline 2: logistic Regression\n",
    "\n",
    "baseline_log_reg = LogisticRegression(max_iter=1000, solver='lbfgs', n_jobs=1)\n",
    "baseline_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make probability predictions for X_train\n",
    "train_probs2 = baseline_log_reg.predict_proba(X_train)[:, 1]\n",
    "train_predictions2 = baseline_log_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results X_train prediction:\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs2)}')\n",
    "print(confusion_matrix(y_train, train_predictions2))\n",
    "print(classification_report(y_train, train_predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make probability predictions for X_test\n",
    "test_probs2 = baseline_log_reg.predict_proba(X_test)[:, 1]\n",
    "test_predictions2 = baseline_log_reg.predict(X_test)\n",
    "\n",
    "# Results X_test prediction:\n",
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, test_probs2)}')\n",
    "print(confusion_matrix(y_test, test_predictions2))\n",
    "print(classification_report(y_test, test_predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 1000 trees\n",
    "model1 = RandomForestClassifier(n_estimators=1000, \n",
    "                               random_state=RSEED, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)\n",
    "\n",
    "# Fit on training data\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for X_train\n",
    "train_probs_1 = model1.predict_proba(X_train)[:, 1]\n",
    "train_predictions_1 = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results X_train prediction:\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs_1)}')\n",
    "print(confusion_matrix(y_train, train_predictions_1))\n",
    "print(classification_report(y_train, train_predictions_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for X_test\n",
    "test_probs_1 = model1.predict_proba(X_test)[:, 1]\n",
    "test_predictions_1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results X_test prediction:\n",
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, test_probs_1)}')\n",
    "print(confusion_matrix(y_test, test_predictions_1))\n",
    "print(classification_report(y_test, test_predictions_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Stacking\n",
    "<span style=\"color:red\">Integrate GridSearchCV or RandomizedGridSearchCV!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the models Decision Tree, KNN and Random Forest\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier(random_state = RSEED)),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('rf', RandomForestClassifier(random_state = RSEED))\n",
    "]\n",
    "\n",
    "# Fit model to training data\n",
    "model2 = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression())\n",
    "model2.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for X_train\n",
    "train_probs_2 = model2.predict_proba(X_train)[:, 1]\n",
    "train_predictions_2 = model2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results X_train prediction:\n",
    "print(f'Train ROC AUC Score: {roc_auc_score(y_train, train_probs_2)}')\n",
    "print(confusion_matrix(y_train, train_predictions_2))\n",
    "print(classification_report(y_train, train_predictions_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for X_test\n",
    "test_probs_2 = model1.predict_proba(X_test)[:, 1]\n",
    "test_predictions_2 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results X_test prediction:\n",
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, test_probs_2)}')\n",
    "print(confusion_matrix(y_test, test_predictions_2))\n",
    "print(classification_report(y_test, test_predictions_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model to training data\n",
    "model3 = XGBClassifier(random_state=RSEED,\n",
    "                    n_jobs=-1,\n",
    "                    n_estimators=1000,\n",
    "                    learning_rate=0.3,\n",
    "                    subsample=0.5,\n",
    "                    )\n",
    "                    \n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOCH ANZUPASSEN!\n",
    "\n",
    "\n",
    "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
    "    \"\"\"Compare machine learning model to baseline performance.\n",
    "    Computes statistics and shows ROC curve.\"\"\"\n",
    "    \n",
    "   baseline_tree = {}\n",
    "    \n",
    "   baseline_tree['recall'] = recall_score(y_test, [1 for _ in range(len(y_test))])\n",
    "   baseline_tree['precision'] = precision_score(y_test, [1 for _ in range(len(y_test))])\n",
    "   baseline_tree['roc'] = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "   baseline_log_reg = {}\n",
    "    \n",
    "   baseline_log_reg['recall'] = recall_score(y_test, [1 for _ in range(len(y_test))])\n",
    "   baseline_log_reg['precision'] = precision_score(y_test, [1 for _ in range(len(y_test))])\n",
    "   baseline_log_reg['roc'] = roc_auc_score(y_test, y_probs)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, predictions)\n",
    "    results['precision'] = precision_score(y_test, predictions)\n",
    "    results['roc'] = roc_auc_score(y_test, probs)\n",
    "    \n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(train_labels, train_predictions)\n",
    "    train_results['precision'] = precision_score(train_labels, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(train_labels, train_probs)\n",
    "    \n",
    "    for metric in ['recall', 'precision', 'roc']:\n",
    "        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(y_test))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
